\section{Introduction}
% è®²æ•…äº‹ä¸»çº¿ï¼šå…ˆè¯´``ä¸ºä»€ä¹ˆéœ€è¦/ç°åœ¨ç¼ºä»€ä¹ˆ''ï¼Œå†è¯´``æˆ‘ä»¬é€‰æ‹©ä»€ä¹ˆè·¯å¾„ä¸å£å¾„''ï¼Œç»™å‡º``ç³»ç»Ÿé¢„è§ˆä¸è®¾è®¡åŸåˆ™''ï¼Œç‚¹å‡º``å…³é”®æŒ‘æˆ˜''ï¼Œæœ€åæ˜ç¡®``ç›®æ ‡/äº¤ä»˜ç‰©/è¾¹ç•Œ''ã€‚å¼•ç”¨ä»¥ä»£è¡¨æ€§è®ºæ–‡ä¸ºè¯ï¼Œä¸å †æ ˆã€‚

% ==========
% 1.1 Problem Statement & Motivation
% ==========
\subsection{Problem Statement \& Motivation}
% Why worthy? (Passion, market, need)
% Demand -> Neuro-sama (success on market and tech) -> Timely: recent research support -> Project Definition

The demand for \textbf{interactive and companion-like experiences} in real-time entertainment is rapidly growing, with players seeking more than just simple automation or static overlays. As the landscape of interactive experiences evolves, the focus is shifting towards genuine engagement and companionship, with players desiring dynamic, responsive partners that enhance their overall experience.

On the one hand, games like AI2U: ``With You 'Til The End'' are already capitalizing on this trend, drawing players in with the novelty of engaging with generative AI characters \cite{ai2u_game}. At the same time, larger companies are investing in foundational technologies like NVIDIA's ACE (Avatar Cloud Engine) and Ubisoft's ``NEO NPCs'', aiming to create autonomous agents that enhance gameplay rather than just drive conversation~\cite{nvidia_ace_autonomous_2025, ubisoft_neo_npc_2024}. These shifts in the gaming industry are validating the commercial viability of AI-driven experiences, as evidenced by increased player engagement and media interest~\cite{inworld_market_validation_2023}.

On the other hand, the rise of AI-driven virtual streamers, particularly the Neuro-sama phenomenon, highlights a significant shift in both technology and community-driven commercialization. Neuro-sama, an AI-powered virtual streamer (VTuber), engages in real-time conversations and dynamic gameplay, capturing the attention of audiences \cite{neurosama_youtube, streamelements_state_2024, streamscharts_q4_2024_landscape}. Although Neuro-sama remains closed-source, its success has inspired a vibrant open-source ecosystem, with developers aiming to replicate or expand upon its capabilities \cite{open_llm_vtuber, airi_project, kimjammer_neuro}. This technological innovation has been accompanied by strong commercial traction on platforms like Twitch, indicating a growing market demand for AI that offers both utility and companionship \cite{neurosama_hype_streamscharts_2025}.

% This project is timely. While the market demand is clear, the technological feasibility for a \textbf{reproducible, non-API-dependent} assistant has only recently emerged. Foundational research is now converging on the key methodologies required for productization. This includes the development of \textbf{unified evaluation protocols} and \textbf{modular ablation frameworks}, which are essential for ensuring that experiments are reproducible and comparable \cite{ORAK, lmgame-bench}. Furthermore, recent work has demonstrated the viability of \textbf{General Computer Control (GCC)} pathways (i.e., screen-in, keyboard/mouse-out), confirming that capable agents can operate without relying on game-specific APIs \cite{CRADLE, ui-venus}.

\todo{Consider whether to remove the previous paragraph about ``timely''}

Inspired by this clear convergence of market demand and emerging academic feasibility, this project aims to bridge the gap. The core objective is to define and build a prototype for a \textbf{companion-style assistant}. This assistant is envisioned as a persistent, in-game partner that delivers \textbf{event spotting} and \textbf{tactical guidance}, leveraging these new, reproducible methodologies to enhance the player's experience without interrupting gameplay.

\todo{Consider to improve this paragraph after finishing other parts}

\subsection{Scope, Objectives, and Deliverables}

\paragraph{Scope} 
This project aims to develop a system that addresses the challenges of inconsistent action interfaces and the limitations of relying on platform-specific implementations. The technical scope, including the boundaries of what will and will not be addressed, is as follows:

\begin{enumerate}
    \item \textbf{Unified Action Interface via GUI (GCC)}: The system will utilize a human-homomorphic interface with a screen-in, keyboard/mouse-out paradigm. This eliminates the need for platform-specific interfaces or game-specific programming interfaces (APIs), ensuring adaptability across different platforms without requiring specialized API integration \cite{CRADLE, ui-venus}.
    
    \item \textbf{Constrained Action Generation with Structured Output}: Actions will be selected from a predefined set of valid actions (e.g., "move forward," "open inventory") and formatted using a structured output (e.g., JSON). This approach reduces errors such as hallucinations and ensures that the actions generated are legal, predictable, and reproducible. This structured framework guarantees that only valid actions are performed, significantly reducing the risk of errors during real-time operation \cite{Benchmarking-VLA-VLM}.
    
    \item \textbf{Low-Coupling Orchestration}: The system will implement an MCP-style orchestration model that allows modular, plug-and-play components. This modular architecture ensures that new skills or modules can be easily integrated, promoting system scalability and flexibility. It also supports future updates and ablation studies without requiring major overhauls to the system's core structure \cite{ORAK}.
\end{enumerate}



% ==========
% 1.4 Design Principles & System Preview
% ==========
\subsection{Design Principles \& System Preview}
\todo{Put to Section 3. Project Plan, or just remove?}

\paragraph{Design principles.}
This project follows four principles: \textbf{Unified Input} (ensures portability across applications), \textbf{Structured Output} (reduces invalid actions and is easy to audit), \textbf{Protocol Consistency} (ensures reproducibility and ablative evaluation), \textbf{Low-Coupling Orchestration} (MCP-style, facilitates modular insertion/removal of skills/tools).

\paragraph{System preview.}
The system flow is as follows: \textbf{screen/audio} capture, lightweight \textbf{VLM} perception, \textbf{agentic} (planning/memory/reflection) modules, \textbf{MCP-style} skill/tool routing (including OCR/retrieval/computation \textbf{tool use}), \textbf{GUI execution} (keyboard and mouse), and finally passing through the \textbf{safety} module (confirmation/rollback/emergency stop). To reduce end-to-end latency, the deployment strategy will combine the \textbf{tool-augmented MLLM} approach with \textbf{on-device inference} quantization/caching strategies as key engineering tactics \cite{tool-aug-mllm, on-device-llm}.

\todo{$\uparrow$ Not ready yet}



% TODO: æ¨¡å—åŒ–çš„skills/macroï¼Œæ–¹ä¾¿ç¤¾åŒºå¼€å‘é€‚ç”¨äºä¸åŒæ¸¸æˆçš„æ’ä»¶ï¼Ÿâœ…åæœŸå¿…é¡»è¦åŠ 

% TODO: ä¼ ç»™å¤§æ¨¡å‹çš„æ˜¯å¤„ç†åçš„å›¾ç‰‡ï¼Ÿæ¯”å¦‚è¯´ç”¨YOLOæ‰“æ ‡å’Œä½ç½®ï¼ŸğŸ¤”åé¢å†çœ‹