\section{Introduction}
% 讲故事主线：先说“为什么需要/现在缺什么”，再说“我们选择什么路径与口径”，给出“系统预览与设计原则”，点出“关键挑战”，最后明确“目标/交付物/边界”。引用以代表性论文为证，不堆栈。

% ==========
% 1.1 Problem Setting & Motivation
% ==========
\subsection{Problem Setting \& Motivation}
% Why worthy? (Passion, market, need)
% Demand -> Neuro-sama (success on market and tech) -> Timely: recent research support -> Project Definition

The demand for \textbf{companion-style} AI assistants that operate in real-time gaming environments is expanding rapidly. This trend signals a shift in player expectations, moving beyond simple automation scripts or static information overlays toward interactive, persistent, and engaging AI partners.

The rise of AI-driven virtual streamers, particularly the \textbf{Neuro-sama} phenomenon, highlights a significant shift in both technology and community-driven commercialization. Neuro-sama, an AI-powered virtual streamer (VTuber), engages in real-time conversations and dynamic gameplay, capturing the attention of audiences \cite{neurosama_youtube}. Although Neuro-sama remains closed-source, its success has inspired a vibrant open-source ecosystem, with developers aiming to replicate or expand upon its capabilities \cite{open_llm_vtuber,airi_project,kimjammer_neuro}. This technological innovation has been accompanied by strong commercial traction on platforms like Twitch, indicating a growing market demand for AI that offers both utility and companionship \cite{neurosama_hype_streamscharts_2025, vedal_twitchtracker}. Through persistent, low-latency \textbf{voice loops}, these AI systems create engaging player experiences, driving both user engagement and monetization.

This project is timely. While the market demand is clear, the technological feasibility for a \textbf{reproducible, non-API-dependent} assistant has only recently emerged. Foundational research is now converging on the key methodologies required for productization. This includes the development of \textbf{unified evaluation protocols} and \textbf{modular ablation frameworks}, which are essential for ensuring that experiments are reproducible and comparable \cite{ORAK, lmgame-bench}. Furthermore, recent work has demonstrated the viability of \textbf{General Computer Control (GCC)} pathways (i.e., screen-in, keyboard/mouse-out), confirming that capable agents can operate without relying on game-specific APIs \cite{CRADLE, ui-venus}.

	extbf{Inspired by} this clear convergence of market demand and emerging academic feasibility, this project aims to bridge the gap. The core objective is to define and build a prototype for a \textbf{companion-style assistant}. This assistant is envisioned as a persistent, in-game partner that delivers \textbf{event spotting} and \textbf{tactical guidance}, leveraging these new, reproducible methodologies to enhance the player's experience without interrupting gameplay.

% ==========
% 1.2 Scope & Working Definitions
% ==========
\subsection{Project Scope \& Feasibility}

To address the issue of inconsistent action interfaces and the challenge of reproducibility caused by reliance on scene-specific APIs, as mentioned in previous sections, this project makes the following clear definition of its technical scope:

\begin{itemize}
    \item \textbf{Unified action interface via GUI (GCC)}: This refers to a human-homomorphic channel with screen-in, keyboard/mouse-out.
    \item \textbf{Structured output as the default path}: The default action generation and execution path is defined as \textbf{structured output + constrained decoding}.
\end{itemize}

This scope is defined based on its demonstrated feasibility. Existing studies have shown that, without relying on application-specific APIs, long-horizon tasks can be completed through a pipeline consisting of "planning, macro/skill organization, self-reflection, and memory". Additionally, on real platforms, the "screenshot to structured action" end-to-end navigation path has been proven to be reproducible, and \textbf{legal move constraints} significantly reduce invalid actions \cite{CRADLE, ui-venus, Benchmarking-VLA-VLM}.

% ==========
% 1.3 Design Principles & System Preview
% ==========
\subsection{Design Principles \& System Preview}

\noindent\textbf{Design principles.}\par
This work follows four principles: \textbf{Unified Input} (ensures portability across applications), \textbf{Structured Output} (reduces invalid actions and is easy to audit), \textbf{Protocol Consistency} (ensures reproducibility and ablative evaluation), \textbf{Low-Coupling Orchestration} (MCP-style, facilitates modular insertion/removal of skills/tools).

\noindent\textbf{System preview.}\par
The system flow is as follows: \textbf{screen/audio} capture, lightweight \textbf{VLM} perception, \textbf{agentic} (planning/memory/reflection) modules, \textbf{MCP-style} skill/tool routing (including OCR/retrieval/computation \textbf{tool use}), \textbf{GUI execution} (keyboard and mouse), and finally passing through the \textbf{safety} module (confirmation/rollback/emergency stop). To reduce end-to-end latency, the deployment strategy will combine the \textbf{tool-augmented MLLM} approach with \textbf{on-device inference} quantization/caching strategies as key engineering tactics \cite{tool-aug-mllm, on-device-llm}.

% ==========
% 1.4 Key Challenges
% ==========
\subsection{Key Challenges}

In real player scenarios, the challenge is not just the individual model score, but the overall experience that is \textbf{stable, accurate, fast, and controllable}. Below, the challenges are listed according to \textbf{measurable} factors.

\noindent\textbf{Long-Horizon Stability (GCC).} When using only GUI (GCC), errors and misalignments can accumulate along the interaction chain, leading to the problem of “drifting off track.” This can be measured with \textbf{pass@k}, rollback rate, and APO (attempts per opportunity). The combination of “\textbf{planning + skills (macro) + reflection + memory}” can alleviate drift, but it is not a panacea \cite{CRADLE}.

\noindent\textbf{Vision-Centric Grounding \& Memory.} In purely visual or continuous space setups, \textbf{localization/tracking/counting, timing control, and long-term visual memory} are current model limitations. These can be statistically measured by \textbf{OAS} (opportunity-normalized success), broken down by opportunity types such as “pickable items/time points/path nodes” \cite{v-mage}.

\noindent\textbf{Invalid Actions \& Think-Action Mismatch.} Converting free text into actions often results in “thinking correctly but clicking the wrong place.” \textbf{Structured output + legal move constraints} can reduce \textbf{Invalid\%}, and \textbf{Brier/MAE} can be used to evaluate calibration. On the training side, rewards based on four granularities—“format/type/coordinates/content”—align execution details \cite{Benchmarking-VLA-VLM, ui-venus}. At the implementation level, output strategies such as “\textbf{semantic, →, allowed actions}” mapping or \textbf{probability modeling over the set of allowed actions} can be used to suppress out-of-bounds and misaligned actions from the start \cite{llm-ga}.

\noindent\textbf{OOD \& Protocol Consistency.} When the environment or version changes, comparison results become difficult. \textbf{Procedural generation} is needed for out-of-distribution (OOD) evaluation, with fixed \textbf{post-processing} and prompt scaffolding to control variables, and reporting \textbf{macro/micro} metrics under a \textbf{unified protocol} and \textbf{leaderboard/battle arena} \cite{Benchmarking-VLA-VLM, lmgame-bench, ORAK}.

\noindent\textbf{Latency \& User Experience (UX).} An assistant must “respond instantly.” The key metrics are \textbf{RT} (reaction time per opportunity) and \textbf{voice RTT} (round-trip voice latency). Engineering strategies to reduce latency include \textbf{quantization/pruning/KV caching/streaming decoding} and \textbf{on-device/edge-cloud collaboration}, along with single-flight and barge-in strategies \cite{on-device-llm}.

\noindent\textbf{Safety \& Robustness.} High-risk actions must be “confirmable, rollbackable, and traceable.” The approach includes \textbf{permission whitelists}, \textbf{double confirmation}, \textbf{shadow execution}, and \textbf{rollback/emergency stop}, with \textbf{logging/auditing} to locate \textbf{think-action mismatch} \cite{llm-brained-gui, mllm-gui, os-agents}.

% ==========
% 1.5 Project Objectives & Expected Deliverables
% ==========
\subsection{Project Objectives \& Expected Deliverables}

\noindent\textbf{Objectives.} 
\begin{itemize}
    \item [(i)] Develop a \textbf{GCC-based} \textbf{assistant} real-time prototype that covers event prompting, strategy suggestions, and voice loops. 
    \item [(ii)] Organize \textbf{skills/macros, planning, memory, reflection} using \textbf{MCP-style orchestration}, enabling plug-and-play and auditability without relying on application-specific APIs.
    \item [(iii)] Define a set of \textbf{small and reproducible} evaluation elements (task scripts and metric families), focusing on \textbf{pass@k/TTC/Invalid\%/macro-micro} and \textbf{OAS/RT/APO} experience-related metrics \cite{ORAK, lmgame-bench}.
\end{itemize}

\noindent\textbf{Expected Deliverables.} 
\begin{itemize}
    \item [(a)] \textbf{System Prototype:} Screen capture and lightweight perception, agentic modules, MCP-style skill bus, GUI executor, and basic safety safeguards.
    \item [(b)] \textbf{Evaluation Scripts and Configuration:} Reproducible task scripts, metric calculation, and logging/audit tools (including module switches for comparison).
    \item [(c)] \textbf{User Documentation and Demos:} Installation/operation instructions, configuration templates, and demo videos.
\end{itemize}

% ==========
% 1.6 Assumptions & Out-of-Scope
% ==========
\subsection{Assumptions \& Out-of-Scope}

\noindent\textbf{Working assumptions.}\par
The default engineering posture is \textbf{single-flight + event-triggered + frame-window (3–5 frames) + text-first} to reduce latency and variance. Evaluation records \textbf{post-processing} and environment versions will be maintained to ensure protocol consistency.

\noindent\textbf{Out-of-scope.}\par
 This project does not involve \textbf{adapting application/game-specific APIs} on a per-application basis. It does not commit to \textbf{large-scale end-to-end training and data collection} in this report. It will not rely on platform-level enhancement privileges (such as A11y/private DOM hooks). \textbf{VLA direct-action} will be used only as a benchmark comparison and not as the default path \cite{Benchmarking-VLA-VLM}.

% ==========
% 1.7 术语与范围对齐（Glossary \& Scope Alignment）
% ==========
\subsection{Glossary \& Terminology}

\noindent\todo{Add more \dots}

Since this research area is relatively new, the terminology and naming conventions across different works are not yet unified. Therefore, before entering the literature review, this work aligns key terms and definitions:

\noindent\textbf{GCC (General Computer Control):} A human-homomorphic action interface defined as screen-in + keyboard/mouse-out; this is the default execution channel in this work \cite{llm-brained-gui}.

\noindent\textbf{LAM (Large Action Models):} A family of models where structured actions are treated as first-class outputs; referenced as a comparative paradigm in this work \cite{llm-brained-gui}.

\noindent\textbf{VLM vs VLA:} Text/JSON output mapped into action space vs direct action vectors/distributions; evaluation will consistently use legal move mapping + constrained decoding approach \cite{mllm-gui}.

\noindent\textbf{Scaffold vs Orchestration (MCP-style):} The former refers to the stable interaction "scaffolding" during evaluation, while the latter refers to module/tool registration and routing; both are complementary \cite{os-agents}.

\noindent\textbf{Metric Definitions:} \textbf{pass@k}, \textbf{TTC}, \textbf{Invalid\%}, and \textbf{macro/micro} will be reported together; opportunity-driven \textbf{OAS/RT/APO} serve as core supplements in companion-style scenarios \cite{agent-ai}.

\noindent\textbf{Memory–Reasoning–I/O (M-R-I/O):} The internal working division and terminology anchor of this work. Here, planning and reflection align with reasoning, skills/macros represent action output forms on the I/O side, and memory remains independent. The output side will default to a “semantic-to-allowed action” mapping or a compliance strategy that models probabilities over the set of allowed actions \cite{llm-ga}.


% TODO: “虽然现在有类似于MAA、BetterGI、三月七小助手”这样的软件，但是他们主要是基于传统图像识别的自动化脚本，虽然能提升玩家体验，但是难以提供情感支持。

% TODO: 模块化的skills/macro，方便社区开发适用于不同游戏的插件？

% TODO: 传给大模型的是处理后的图片？比如说用YOLO打标和位置？