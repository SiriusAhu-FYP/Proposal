\section{Introduction}
% 讲故事主线：先说“为什么需要/现在缺什么”，再说“我们选择什么路径与口径”，给出“系统预览与设计原则”，点出“关键挑战”，最后明确“目标/交付物/边界”。引用以代表性论文为证，不堆栈。

% ==========
% 1.1 Problem Setting & Motivation
% ==========
\subsection{Problem Setting \& Motivation}
% 作用：把“伴随式实时助手”的使用图景与缺口（统一动作接口、可复现实验）讲清楚，并以代表性基准/综述作为证据引入。

面向玩家的\emph{伴随式（companion-style）}实时助手，目标是在\textbf{不打断游戏流程}的前提下，持续提供\emph{事件提示（event spotting）}、\emph{策略建议（tactical guidance）}与\emph{语音回路（voice loop）}的低时延体验。近年的\emph{LLM$\times$游戏}与\emph{GUI 智能体}研究快速推进，但落地层面仍存在两类缺口：一是\textbf{动作接口不统一}，大量工程依赖场景定制；二是\textbf{评测协议不一致}，导致复现实验与横向对比困难。围绕这些缺口，已有工作正从\emph{统一协议/消融}与\emph{脚手架/污染控制}两侧收敛可复现方法学，为产品化路径提供操作依据\cite{ORAK,lmgame-bench,gp-agents}。同时，近期综述将 LLM 游戏智能体抽象为\emph{记忆—推理—I/O}三件套，并强调 I/O 质量与\emph{允许动作集合}的一致性是交互成败的关键，这与“结构化输出/约束解码”的工程路径相吻合\cite{llm-ga}。

% ==========
% 1.2 Scope & Working Definitions
% ==========
\subsection{Scope \& Working Definitions}
% 作用：用“工作定义”定下本文的口径：执行通道（GCC）、编排方式（MCP-style）、输出形态（结构化输出/约束解码）、评测抓手（统一协议与事件型指标）。

本项目选择\textbf{以 GUI（GCC）为统一动作接口}（\emph{screen-in, keyboard/mouse-out} 的人类同态通道），并以\textbf{结构化输出（structured output）+ 约束解码（constrained decoding）}作为默认的动作生成与落地路径。已有研究表明：在\emph{不依赖应用专用 API} 的前提下，通过“规划—技能整理（macro/skill）—自反思—记忆”的管线可跑通长链路任务；在真实平台上，“\emph{截图} $\rightarrow$ \emph{结构化动作}”的端到端导航具有可复现性，且\emph{合法动作映射（legal move constraint）}能够显著降低无效动作（invalid actions）\cite{CRADLE,ui-venus,Benchmarking-VLA-VLM}。内部组织采用\textbf{MCP-style 编排}（模块/技能/工具的注册与路由），支撑消融与替换；评测遵循\textbf{统一协议+脚手架} 的做法，并引入\emph{机会导向}的 OAS/RT/APO 三项工作定义以刻画伴随式体验\cite{ORAK,lmgame-bench}。为避免名词漂移，本文将\textbf{记忆—推理—I/O}作为术语锚点：\emph{planning+reflection} 对齐 \emph{reasoning}，\emph{skills/macros} 属于 \emph{I/O} 侧的动作产出形态，\emph{memory} 独立；输出端默认遵循“语义\,$\rightarrow$\,允许动作”映射或\emph{在允许集合上建模概率}的合规策略\cite{llm-ga}。

% ==========
% 1.3 Design Principles & System Preview
% ==========
\subsection{Design Principles \& System Preview}
% 作用：一句话系统流＋设计原则；把“为什么这样设计”与前文证据钩住；引入端侧/工具增强作为工程抓手。

\noindent\textbf{Design principles.}
本文遵循四项原则：\textbf{结构化输出}（降低无效/便于审计）、\textbf{协议一致}（可复现/可消融）、\textbf{低耦合编排}（MCP-style，便于插拔 skills/tools）、\textbf{低时延}（面向 voice loop 与事件提示）。  

\noindent\textbf{System preview.}
系统流为：\emph{screen/audio} $\rightarrow$ 轻量\emph{VLM} 感知 $\rightarrow$ \emph{agentic}（planning/memory/reflection）$\rightarrow$ \emph{MCP-style} 技能/工具路由（含 OCR/检索/计算等 \emph{tool use}）$\rightarrow$ \emph{GUI 执行}（kb/mouse）$\rightarrow$ \emph{safety}（确认/回滚/急停）。为降低端到端时延，部署层面将结合\emph{工具增强型 MLLM} 的分担思路与\emph{端侧推理}的量化/缓存策略作为工程抓手\cite{tool-aug-mllm,on-device-llm}。

% ==========
% 1.4 Key Challenges
% ==========
\subsection{Key Challenges}
% 作用：把“落到玩家侧真正难的事”说清楚，用通俗句式说明——为什么重要、怎么量、文献怎么佐证；为后文评测与设计留钩子（OAS/RT/APO、结构化输出、脚手架等）。

落到真实玩家场景，难点不是单一模型分数，而是\textbf{稳、准、快、可控}的整体体验。下面按\emph{可测}的挑战项列出。

\noindent\textbf{长链路稳定（long-horizon stability, GCC）。}
只走 GUI（GCC）时，误点与偏移会沿交互链放大，导致“走着走着就跑偏”。可用 \emph{pass@k}、回滚率（rollback）与 \textbf{APO}（attempts per opportunity）来量；\;“\emph{planning + skills（macro）+ reflection + memory}”的组合能缓解漂移，但并非万灵药\cite{CRADLE}。

\noindent\textbf{视觉定位与记忆（vision-centric grounding \& memory）。}
在仅视觉/连续空间设定下，\emph{定位/追踪/计数、时机控制、长期视觉记忆}是当前模型短板，可按\textbf{OAS}（opportunity-normalized success）分机会类型统计，如“可拾取物/时间点/路径节点”等\cite{v-mage}。

\noindent\textbf{无效动作与幻觉（invalid actions \& think–action mismatch）。}
自由文本到动作容易“想得对、点错位”。\textbf{结构化输出 + 合法动作映射}能够压低 \emph{Invalid\%}，并可用 \emph{Brier/MAE} 看校准；训练侧以“格式/类型/坐标/内容”四粒度奖励对齐执行细节\cite{Benchmarking-VLA-VLM,ui-venus}。在实现层面，还可采用“\emph{语义\,$\rightarrow$\,允许动作}”映射或\emph{在允许动作集合上建模概率}的输出策略，从源头抑制越界与错位\cite{llm-ga}。

\noindent\textbf{OOD 与协议一致（OOD \& protocol consistency）。}
环境一换、版本一更，成绩就难对比。需要\emph{过程生成}（procedural generation）做分布外（OOD）评测，固定 \emph{post-processing} 与提示脚手架（scaffold）控变量，并在\emph{统一协议}与 \emph{leaderboard/battle arena} 下报告 \emph{macro/micro} 指标\cite{Benchmarking-VLA-VLM,lmgame-bench,ORAK}。

\noindent\textbf{时延与交互体验（latency \& UX）。}
伴随式助手要“当下就回应”。关键是\textbf{RT}（reaction time per opportunity）与 \emph{voice RTT}（语音往返）。工程上依赖\emph{量化/剪枝/KV 缓存/流式解码}与\emph{端侧/端云协同}压时延，搭配单航班（single-flight）与可打断（barge-in）策略\cite{on-device-llm}。

\noindent\textbf{安全与健壮性（safety \& robustness）。}
高风险动作必须“可确认、可回退、可追溯”。做法包括\emph{权限白名单}、\emph{双确认}、\emph{影子执行（shadow execution）}与\emph{回滚/急停}，并保存\emph{日志/审计}定位 \emph{think–action mismatch}\cite{llm-brained-gui,mllm-gui,os-agents}.

% ==========
% 1.5 Project Objectives & Expected Deliverables
% ==========
\subsection{Project Objectives \& Expected Deliverables}
% 作用：以“产品向”列目标与交付物，不写研究承诺；指标对齐前文口径。

\noindent\textbf{Objectives.}
(i) 实现一个\textbf{以 GCC 为主}的\emph{伴随式}实时助手原型，覆盖事件提示、策略建议与语音回路；(ii) 采用\textbf{MCP-style 编排}组织 \emph{skills/macros、planning、memory、reflection}，在不依赖应用专用 API 的前提下实现可插拔与可审计；(iii) 明确一套\textbf{小而可复现}的评测要素（任务脚本与指标族），关注 \emph{pass@k/TTC/Invalid\%/macro–micro} 以及 \emph{OAS/RT/APO} 等体验相关量\cite{ORAK,lmgame-bench}.  

\noindent\textbf{Expected deliverables.}
(a) \textbf{系统原型}：屏幕采集与轻量感知、agentic 模块、MCP-style 技能总线、GUI 执行器与基础安全护栏；(b) \textbf{评测脚本与配置}：可复现实验的任务脚本、指标计算与日志审计工具（含模块开关用于对照）；(c) \textbf{使用文档与演示}：安装/运行说明、配置模板与演示视频。

% ==========
% 1.6 Assumptions & Out-of-Scope
% ==========
\subsection{Assumptions \& Out-of-Scope}
% 作用：提前声明工程与范围假设，降低评审对“宽口径”的不确定；与部署/评测呼应。

\noindent\textbf{Working assumptions.}
默认采用“\emph{single-flight + event-triggered + frame-window（3–5 帧）+ text-first}”的工程姿态以降低时延与方差；评测记录\emph{post-processing} 与环境版本以保持协议一致。  

\noindent\textbf{Out-of-scope.}
不开展\textbf{逐个应用/游戏的专用 API 适配}；不在本报告中承诺\textbf{大规模端到端训练与数据采集}；不依赖平台级增强权限（如 A11y/私有 DOM 钩子）；\textbf{VLA 直出动作}仅作为评测对照而非默认路径\cite{Benchmarking-VLA-VLM}.

% ==========
% 1.7 能力边界
% ==========
\subsection{能力边界（Capability Gaps）}
% 作用：直面“做不到哪儿”，把失败模式与短板集中呈现，回扣 event spotting / tactical guidance / voice loop 的风险位；作为后续指标与案例设计的负样本清单。

以视觉为中心的自由形式游戏显示，多模态模型在若干关键能力上仍与人类存在差距：\emph{定位/追踪/计数}、\emph{历史依赖与锚定偏置}、\emph{时机控制}、\emph{视觉记忆}、\emph{文本识别与空间理解}以及\emph{高层时序推理}等维度普遍薄弱。采用 Elo 风格相对强度排名与“模型/策略”的管线分离，从评测组织上揭示了这些系统性短板与不稳定性\cite{v-mage}。更通用的 LLM×游戏评测同样显示，\emph{交互稳定性与污染控制}会显著影响结果分离度，提示伴随式场景需要\emph{机会归一化}与\emph{反应时}等细粒度度量以及脚手架约束\cite{lmgame-bench}。

% ==========
% 1.8 术语与范围对齐（glossary box）
% ==========
\subsection{术语与范围对齐（Glossary \& Scope Alignment）}
% 作用：避免跨论文叫法不一导致的混淆；不引入新结论，仅固定本文口径。建议在排版中做成“灰底小盒/附录小表”，此处用行内加粗标示。
% 证据来源：多篇综述的共识视角\cite{agent-ai,llm-brained-gui,mllm-gui,os-agents}；必要时在部署节再补 on-device 与更广游戏综述\cite{on-device-llm,gp-agents}。

\textbf{GCC（General Computer Control）}：\emph{screen-in + keyboard/mouse-out} 的人类同态动作接口；本文默认执行通道\cite{llm-brained-gui}.  
\textbf{LAM（Large Action Models）}：以\emph{结构化动作}为一等产出的模型族；本文作为对照范式引用\cite{llm-brained-gui}.  
\textbf{VLM vs VLA}：\emph{文本/JSON 输出经映射}进入动作空间 vs \emph{直接动作向量/分布}；评测统一采用\emph{合法动作映射 + 约束解码}口径\cite{mllm-gui}.  
\textbf{Scaffold vs Orchestration（MCP-style）}：前者为评测期稳定交互“脚手架”，后者为模块/工具注册与路由；二者互补\cite{os-agents}.  
\textbf{指标口径}：\emph{pass@k}、\emph{TTC}、\emph{Invalid\%}、\emph{macro/micro} 并报；机会导向的 \textbf{OAS/RT/APO} 为伴随式场景核心补充\cite{agent-ai}.  
\textbf{记忆—推理—I/O（memory–reasoning–I/O）}：本文的内部工作划分与术语锚点；\emph{planning+reflection}→\emph{reasoning}，\emph{skills/macros}→\emph{I/O}，\emph{memory} 独立；输出端遵循“语义\,$\rightarrow$\,允许动作”或\emph{在允许集合上建模概率}的合规策略\cite{llm-ga}.

% TODO: “虽然现在有类似于MAA、BetterGI、三月七小助手”这样的软件，但是他们主要是基于传统图像识别的自动化脚本，虽然能提升玩家体验，但是难以提供情感支持。

% TODO: 模块化的skills/macro，方便社区开发适用于不同游戏的插件？

% TODO: 传给大模型的是处理后的图片？比如说用YOLO打标和位置？