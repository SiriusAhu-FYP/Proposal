\section*{Abstract}
\fontfamily{ptm}\selectfont
\justifying % 需要加载 ragged2e 宏包
\noindent
The demand for interactive, companion-style AI in real-time entertainment is rising, yet current academic research is largely bifurcated, focusing on either purely functional task-completion or the fundamentals of relational AI. This project addresses this gap by designing, building, and validating a \textbf{novel, unified architecture} that blends both functional agency and proactive companionship. The proposed methodology is a hierarchical, modular system built on the game-agnostic \textbf{General Computer Control (GCC) ``screen-in, keyboard/mouse-out''} paradigm. This system features a central ``Orchestrator'' that receives input from a lightweight perception module (e.g., YOLO) and delegates tasks to specialized, ``plug-and-play'' sub-modules via a \textbf{Model Context Protocol (MCP)} bus. These modules include a \textbf{Functional Core} for in-game actions (using a hybrid-latency model), a \textbf{Proactive Relational Core} (with a Live2D frontend) for companionship, and a \textbf{Safety Core} for error detection and recovery. The project will be validated using a rigorous, two-phased plan: first, functional competence will be tested in logic-based games (e.g., \textit{2048, Stardew Valley}), followed by a qualitative A/B user study in a complex, high-DOF environment (\textit{Minecraft, Genshin Impact}) to prove the unified system provides a measurably superior user experience. The primary contribution of this work will be a validated architectural blueprint for this new class of ``companion-agents'', demonstrating a prototype capable of the deeper, functional partnership that current literature lacks.