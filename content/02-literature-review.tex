\section{Literature Review}
% > 说明：按taxonomy组织；每小节末有“与本文关系”。Cradle放在2.2（GUI/GCC）。涉及了2.1-2.9。

\subsection{Perception: Modalities \& Grounding}
% > 输入模态与定位。涉及2.3-2.4。
\todo{视觉为主（screen/video）+ 可选音频（audio）；VLM能力：检测/描述/grounding；可简单对照VLA（直接产出action tokens）与VLM+tool的差别。
与本文：选轻量VLM，优先本地（on-device）与流式ASR/TTS。}

\subsection{Action Interfaces: GUI (GCC) \& MCP}
% > 动作接口核心小节，放Cradle作“GUI可行性”的代表；并解释MCP作为模块化编排思想。涉及2.6-2.7。
在动作接口上，\textbf{GUI} 路线以 \textbf{General Computer Control (GCC)} 为统一通道（\emph{screen-in, keyboard/mouse-out}），强调对不同应用/游戏的可迁移性（portability）与统一的人类同态交互（human-homomorphic interface）。代表性工作 \emph{Cradle} 显示出在不依赖应用专用接口的前提下，仍可通过\emph{规划—技能整理（skill curation/registry）—反思—记忆}的管线完成长链路任务（desktop/games），从而为\emph{GUI} 的可行性提供了强证据（evidence）。与此同时，\textbf{MCP}（Model Context Protocol）为\emph{模块注册/编排（module registration/orchestration）}提供协议化思路：在不改变输出仍为\emph{GUI}的前提下，可将\emph{skills/macros、planning、memory、reflection}等以统一接口组织起来，便于系统性消融与复用（plug-and-play）。与本文：我们采用\emph{GUI（GCC）}作为唯一执行通道，并借鉴\emph{MCP} 的注册/编排思想作为内部“技能总线（skill bus）”，统一路由与调用\emph{skills/macros} 等模块。\cite{tan2024cradle,park2025orak}

\paragraph{Takeaway}
基于文献可见：\emph{GUI（GCC）}为跨应用/跨游戏提供了统一接口与较低的移植门槛；协议化编排（如\emph{MCP}）可在\emph{不更改GUI输出}的条件下提升模块化与可复现性。与本文：坚持\emph{GUI}输出，内部采用\emph{MCP-style} 编排以获得结构化、可消融的系统形态。

\subsection{Agentic Modules: Planning, Memory, Reflection, Skills}
% > 机制视角。涉及2.1, 2.2, 2.4。
\todo{规划（planning）、记忆（memory, 用户偏好/历史）、反思（self-reflection, 纠错/风格一致）、技能库（skills/macros, 原子→复合）。
与本文：直接采纳skills+reflection+memory组合，并通过“技能总线”统一管理。}

\subsection{Learning Paradigms: Zero-shot, RAG, Finetune, IL/RL, Distillation}
% > 训练与推理范式。涉及2.1, 2.3。
\todo{零样本/提示工程、检索增强（RAG for UI schema/FAQ）、轻量微调（LoRA）、模仿/强化（IL/RL）、蒸馏到小模型。
与本文：优先零样本+RAG，必要时小规模LoRA以稳UI。}

\subsection{Benchmarks \& Datasets (OS-like, Games, Desktop)}
% > 基准版图。涉及2.6。
以真实多类型游戏为对象的统一评测框架正在兴起：\emph{Orak} 通过 \emph{MCP} 实现\emph{plug-and-play} 的代理—环境解耦，并在统一配置下检验 \emph{planning / reflection / memory / skills} 等\emph{agentic modules} 的边际贡献（ablation），配套 \emph{Leaderboard/Battle Arena} 的对比体例与用于训练的轨迹数据（fine-tuning trajectories）。这类框架的价值在于：\emph{机制—性能—配置}三者被一体化呈现，既利于横向（模型/模态）又利于纵向（策略/模块）比较。与本文：我们借鉴其“统一评测 + 消融”的组织方式，但将\emph{输出统一为GUI}，并用\emph{MCP-style} 在内部完成技能与模块的注册/编排。\cite{park2025orak}

% > 说明：该文提供“程序生成→开放式→统一对比”的方法学参考；与GUI并不冲突。
与以真实多类型游戏构建统一评测与消融的框架相互补充，一条重要的发展脉络是基于\emph{procedural generation}的开放式评测：在可控生成下构造\emph{OOD}与多步任务压力，统一比较\emph{VLA/VLM}在\emph{架构/训练数据/输出后处理}等变量下的泛化与稳健性，并配套可复用的工具链以保证\emph{reproducibility}。我们采纳其“\emph{协议一致、变量可控}”的组织方式，但将动作执行统一为\emph{GUI}，并用\emph{MCP-style}在内部编排\emph{skills/macros}与\emph{agentic modules}以适配我们的场景需求\cite{guruprasad2025benchmarking}.

% Lit. Review: Benchmarks & Datasets（与 Orak 并列）
与面向真实多类型游戏的统一评测/消融框架互补，\emph{lmgame-Bench} 将“\emph{游戏→评测}”系统化：用 \emph{Gym-style} 接口与\emph{perception/memory scaffolds} 稳定\emph{prompt}、剔除\emph{污染}，在多模型下获得良好分离度，并通过\emph{相关性分析（correlation analysis）}展示“各游戏探测的能力混合并不相同”；进一步，单一游戏的 \emph{RL} 训练对\emph{未见游戏}与\emph{外部规划任务}出现迁移（transfer）。本文沿用其“\emph{协议一致、变量可控}”的评测方法学，但\textbf{执行端统一为 GUI}，并以 \emph{MCP-style} 在内部编排 \emph{skills/macros} 与 \emph{planning/memory/reflection} 以做可复现实验\cite{hu2505lmgame}.


\subsection{Evaluation Protocols \& Metrics}
% > 强关联本文贡献。涉及2.2, 2.7。
\todo{客观：success rate, time-to-completion, no-misclick/rollback rate, latency（voice RTT, frame→hint时间）；主观：advice adoption, user satisfaction。
与本文：将advice adoption与macro success设为核心指标，配套延迟与稳定性度量。}

% > 说明：把“输出后处理（post-processing）”归入可控变量，便于可复现实验。
为避免实现细节带来的不可比性，我们将输出结构化与解码约束（structured output \& constrained decoding）纳入统一协议：动作以 JSON Schema 与白名单规范，经 MCP-style skill bus 路由后由 GUI 执行；并以 Invalid Action Rate 作为守门指标（目标近零）。在效果度量上，我们采用跨技能均值（macro-averaged success/recall）为主视角，辅以 micro 指标；对稀疏/时序敏感技能，额外报告机会归一化成功率（OAS）、\textbf{反应时延（RT）与每次机会尝试数（APO）}以刻画稳定性与可用性。\cite{guruprasad2025benchmarking}

我们将“\emph{输出后处理（post-processing）}”（如技能解码、重试/回滚策略）显式纳入可控变量，配合\emph{稳定 prompt 与污染控制}的协议，减少实现细节对可比性的干扰\cite{hu2505lmgame}.

\subsection{Deployment \& Real-time Considerations}
% > 工程现实。涉及2.2, 2.6。
\todo{本地/云混合、量化（INT4/FP8）、流式解码、语音中断（barge-in）、资源占用与帧率影响。
与本文：给出延迟预算（如 $\leq 500$ms 提示、$\leq 1.5$s 语音回路）。}

\subsection{Safety, Permissions \& Robustness}
% > 安全边界。涉及2.2。
\todo{权限模型（whitelist, scope）、操作确认、影子模式（shadow mode）先预测后执行、回滚/急停。
与本文：作为系统必要模块并与“技能总线”联动。}

\subsection{Synthesis: Trends, Gaps \& Our Niche}
% > 综述收束到本文位置。关联全篇。
当前趋势是在\emph{GUI（GCC）}的统一通道上引入\emph{协议化/模块化}的编排（如\emph{MCP-style}），以便做机制消融与可复现实验；真实多类型游戏的统一评测（如\emph{Orak}）正在成为共识。缺口在于：\emph{实时伴随式（companion-style）}场景仍缺乏围绕语音互动与低延迟体验的专门指标与协议。与本文：我们将以\emph{GUI}为唯一执行通道，结合\emph{MCP-style} 编排与伴随式指标，给出可复现的小型协议与演示设置。
