@article{tan2024cradle,
  title   = {Cradle: Empowering foundation agents towards general computer control},
  author  = {Tan, Weihao and Zhang, Wentao and Xu, Xinrun and Xia, Haochong and Ding, Ziluo and Li, Boyu and Zhou, Bohan and Yue, Junpeng and Jiang, Jiechuan and Li, Yewen and others},
  journal = {arXiv preprint arXiv:2403.03186},
  year    = {2024}
}

@article{park2025orak,
  title     = {Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games},
  author    = {Park, Dongmin and Kim, Minkyu and Choi, Beongjun and Kim, Junhyuck and Lee, Keon and Lee, Jonghyun and Park, Inkyu and Lee, Byeong-Uk and Hwang, Jaeyoung and Ahn, Jaewoo and Mahabaleshwarkar, Ameya S. and Kartal, Bilal and Biswas, Pritam and Suhara, Yoshi and Lee, Kangwook and Cho, Jaewoong},
  year      = {2025},
  eprint    = {2506.03610},
  archivePrefix = {arXiv},
  note      = {arXiv:2506.03610}
}

@article{guruprasad2025benchmarking,
  title   = {Benchmarking Vision, Language, \& Action Models in Procedurally Generated, Open Ended Action Environments},
  author  = {Guruprasad, Pranav and Wang, Yangyue and Chowdhury, Sudipta and Sikka, Harshvardhan and Liang, Paul Pu},
  journal = {arXiv preprint arXiv:2505.05540},
  year    = {2025}
}

@article{hu2505lmgame,
  title   = {lmgame-bench: How good are llms at playing games?, 2025a},
  author  = {Hu, Lanxiang and Huo, Mingjia and Zhang, Yuxuan and Yu, Haoyang and Xing, Eric P and Stoica, Ion and Rosing, Tajana and Jin, Haojian and Zhang, Hao},
  journal = {URL https://arxiv. org/abs/2505.15146}
}

@article{jin2024read,
  title   = {Read to play (r2-play): Decision transformer with multimodal game instruction},
  author  = {Jin, Yonggang and Zhang, Ge and Zhao, Hao and Zheng, Tianyu and Guo, Jarvi and Xiang, Liuyu and Yue, Shawn and Huang, Stephen W and He, Zhaofeng and Fu, Jie},
  journal = {arXiv preprint arXiv:2402.04154},
  year    = {2024}
}

@article{gu2025ui,
  title   = {Ui-venus technical report: Building high-performance ui agents with rft},
  author  = {Gu, Zhangxuan and Zeng, Zhengwen and Xu, Zhenyu and Zhou, Xingran and Shen, Shuheng and Liu, Yunfei and Zhou, Beitong and Meng, Changhua and Xia, Tianyu and Chen, Weizhi and others},
  journal = {arXiv preprint arXiv:2508.10833},
  year    = {2025}
}

@article{zheng2025v,
  title   = {V-MAGE: A Game Evaluation Framework for Assessing Vision-Centric Capabilities in Multimodal Large Language Models},
  author  = {Zheng, Xiangxi and Li, Linjie and Yang, Zhengyuan and Yu, Ping and Wang, Alex Jinpeng and Yan, Rui and Yao, Yuan and Wang, Lijuan},
  journal = {arXiv preprint arXiv:2504.06148},
  year    = {2025}
}

% Surveys
@article{durante2024agent,
  title   = {Agent ai: Surveying the horizons of multimodal interaction},
  author  = {Durante, Zane and Huang, Qiuyuan and Wake, Naoki and Gong, Ran and Park, Jae Sung and Sarkar, Bidipta and Taori, Rohan and Noda, Yusuke and Terzopoulos, Demetri and Choi, Yejin and others},
  journal = {arXiv preprint arXiv:2401.03568},
  year    = {2024}
}

@article{zhang2024large,
  title   = {Large language model-brained gui agents: A survey},
  author  = {Zhang, Chaoyun and He, Shilin and Qian, Jiaxu and Li, Bowen and Li, Liqun and Qin, Si and Kang, Yu and Ma, Minghua and Liu, Guyue and Lin, Qingwei and others},
  journal = {arXiv preprint arXiv:2411.18279},
  year    = {2024}
}

@article{tang2025survey,
  title   = {A survey on (m) llm-based gui agents},
  author  = {Tang, Fei and Xu, Haolei and Zhang, Hang and Chen, Siqi and Wu, Xingyu and Shen, Yongliang and Zhang, Wenqi and Hou, Guiyang and Tan, Zeqi and Yan, Yuchen and others},
  journal = {arXiv preprint arXiv:2504.13865},
  year    = {2025}
}

@misc{hu2024agents,
  title     = {Os agents: A survey on mllm-based agents for computer, phone and browser use},
  author    = {Hu, Xueyu and Xiong, Tao and Yi, Biao and Wei, Zishu and Xiao, Ruixuan and Chen, Yurun and Ye, Jiasheng and Tao, Meiling and Zhou, Xiangxin and Zhao, Ziyu and others},
  year      = {2024},
  publisher = {OpenReview}
}

@article{an2025empowering,
  title   = {Empowering Multimodal LLMs with External Tools: A Comprehensive Survey},
  author  = {An, Wenbin and Nie, Jiahao and Wu, Yaqiang and Tian, Feng and Lu, Shijian and Zheng, Qinghua},
  journal = {arXiv preprint arXiv:2508.10955},
  year    = {2025}
}

%Supplement
@inproceedings{goel2024label,
  title     = {Label-free subjective player experience modelling via let's play videos},
  author    = {Goel, Dave and Mahmoudi-Nejad, Athar and Guzdial, Matthew},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume    = {20},
  number    = {1},
  pages     = {46--53},
  year      = {2024}
}

@inproceedings{habibi2023modeling,
  title        = {Modeling player personality factors from in-game behavior and affective expression},
  author       = {Habibi, Reza and Pfau, Johannes and El-Nasr, Magy Seif},
  booktitle    = {2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)},
  pages        = {1--8},
  year         = {2023},
  organization = {IEEE}
}

@article{hooshyar2018data,
  title     = {Data-driven approaches to game player modeling: a systematic literature review},
  author    = {Hooshyar, Danial and Yousefi, Moslem and Lim, Heuiseok},
  journal   = {ACM Computing Surveys (CSUR)},
  volume    = {50},
  number    = {6},
  pages     = {1--19},
  year      = {2018},
  publisher = {ACM New York, NY, USA}
}

@article{xu2024device,
  title   = {On-device language models: A comprehensive review},
  author  = {Xu, Jiajun and Li, Zhiyuan and Chen, Wei and Wang, Qun and Gao, Xin and Cai, Qi and Ling, Ziyuan},
  journal = {arXiv preprint arXiv:2409.00088},
  year    = {2024}
}

@article{xu2024survey,
  title   = {A survey on game playing agents and large models: methods, applications, and challenges. arXiv pre-print},
  author  = {Xu, X and Wang, Y and Xu, C and Ding, Z and Jiang, J and Ding, Z and Karlsson, BF},
  journal = {arXiv preprint arXiv:2403.10249},
  year    = {2024}
}

@inproceedings{NEURIPS2024_5d413e48,
  author    = {Xie, Tianbao and Zhang, Danyang and Chen, Jixuan and Li, Xiaochuan and Zhao, Siheng and Cao, Ruisheng and Hua, Toh Jing and Cheng, Zhoujun and Shin, Dongchan and Lei, Fangyu and Liu, Yitao and Xu, Yiheng and Zhou, Shuyan and Savarese, Silvio and Xiong, Caiming and Zhong, Victor and Yu, Tao},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
  pages     = {52040--52094},
  publisher = {Curran Associates, Inc.},
  title     = {OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2024/file/5d413e48f84dc61244b6be550f1cd8f5-Paper-Datasets_and_Benchmarks_Track.pdf},
  volume    = {37},
  year      = {2024}
}

% Community
@misc{neurosama_youtube,
  author       = {Vedal and Neuro-sama},
  title        = {Neuro-sama Official YouTube Channel},
  howpublished = {\url{https://www.youtube.com/@Neurosama}},
  year         = {2022},
  note         = {Accessed: 2025-10-10}
}


@misc{open_llm_vtuber,
  author       = {Open-LLM-VTuber contributors},
  title        = {Open-LLM-VTuber: An open-source AI VTuber framework},
  howpublished = {\url{https://github.com/Open-LLM-VTuber/Open-LLM-VTuber}},
  year         = {2025},
  note         = {Accessed: 2025-10-10}
}

@misc{kimjammer_neuro,
  author       = {kimjammer},
  title        = {Neuro: A local-model recreation of Neuro-sama},
  howpublished = {\url{https://github.com/kimjammer/Neuro}},
  year         = {2025},
  note         = {Accessed: 2025-10-10}
}

@misc{airi_project,
  author       = {moeru-ai},
  title        = {AIRI: AI waifu / virtual character container inspired by Neuro-sama},
  howpublished = {\url{https://github.com/moeru-ai/airi}},
  year         = {2025},
  note         = {Accessed: 2025-10-10}
}

@misc{ai2u_game,
  author       = {AlterStaff},
  title        = {AI2U: With You â€™Til The End},
  howpublished = {\url{https://store.steampowered.com/app/2880730/AI2U_With_You_Til_The_End/}},
  year         = {2025},
  note         = {Accessed: 2025-10-10}
}
